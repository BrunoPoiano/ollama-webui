# Ollama WebUi
WebUi to interact with Local LLM ollama

Setup ollama as a docker container or global
ollama.com/blog/ollama-is-now-available-as-an-official-docker-image

## Steps to Build
`git clone https://github.com/BrunoPoiano/Ollama-WebUi.git`
`cd Ollama-WebUi`
`docker compose up -d`

App expets the port to be `11434` if you changed, change the link in the .env

## On the browser 
`http://localhost:5173/`


<video src="public/conversation.webm" />